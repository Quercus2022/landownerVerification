#! python3
# testScraper.py - Parse HTML for property report webpage for deeded owner and their address.
import openpyxl
from openpyxl.styles import PatternFill
from openpyxl import load_workbook
from openpyxl import Workbook
import requests
from bs4 import BeautifulSoup
import re


# gets a list of last names from database Excel
def getLastNameList(wsName):
    x = 1
    cells = []
    for i in wsName:
        cell = wsName.cell(row=x, column=6).value
        cells.append(cell)
        x += 1
        if i is False: print(i)
    return cells


# get list of street address from database Excel
def getAddressLst1(wsAdr):
    x = 1
    cells = []
    for i in wsAdr:
        cell = wsAdr.cell(row=x, column=4).value
        cells.append(cell)
        x += 1
        if i is False: print(i)
    return cells


# get list of parcel IDs for database Excel
def getPID(ws):
    x = 1
    cells = []
    for i in ws:
        cell = ws.cell(row=x, column=22).value
        cells.append(cell)
        x += 1
        if i is False: print(i)
    return cells


# extracts for webpage a string with deeded landowners full names including trusts if present
def extractOwner(stew):
    # id is different depending on whether landowner name is a
    # link or not. Only  char difference so a regular expression
    # will take care of it.
    x = stew.find(id=re.compile(r"ctlBodyPane_ctl01_ctl01_lstOwner_ctl01_lnkOwnerName_l..Search"))
    ownerA = x.text  # get any text out of html file
    return ownerA


# extracts from webpage a string with deeded landowners mailing address
def extractAddress(stew):
    tdLst = stew.find(id='ctlBodyPane_ctl01_ctl01_lstOwner_ctl01_lblOwnerAddress')
    # <br> is within address txt
    myTag = tdLst.find_all('br')
    # replace br with space
    myTag[1].replace_with(' ')
    # extract only the text from selected html
    ad1 = tdLst.text
    #split the text into address1(street address) and address2(city)
    ad2 = re.split(r'\w*,\s', ad1)
    ad3 = ad2[0].strip()  # selects street address and strips whitespace
    # removes all spaces from string for easier comparison
    ad4 = ad3.replace(' ', '')
    return ad4


# checks if last name from website matches the one in Excel, returns a Boolean
def lastNameCheck(a, b, c):
    name1 = b[c].split()
    if a == name1[0]:
        return True
    else:
        return False


# checks if address from webpage matches the one in Excel, returns a Boolean
def addressCheck(a, b, c):
    # remove all spaces from string for easier comparison
    adLst = b[c].replace(' ', '')
    if a == adLst:
        return True
    else:
        return False


def checkOutput (own, add, wb, ws, i):
    x = i + 1
    if own is False:
        # Fill row with red
        for cell in ws[x:x]:
            cell.fill = PatternFill(fill_type='solid', start_color='00FF0000', end_color='00FF0000')
    elif add is False:
        # Fill row with red
        for cell in ws[x:x]:
            cell.fill = PatternFill(fill_type='solid', start_color='00FF0000',end_color='00FF0000')
    else:
        # Fill row with green
        for cell in ws[x:x]:
            cell.fill = PatternFill(fill_type='solid', start_color='00008000', end_color='00008000')
    # wb.save('johnson2.xlsx')


xlFile = input('Enter .xlsx file to open: ')  # reference spreadsheet
try:
    wb1 = openpyxl.load_workbook(xlFile)  # open spreadsheet
    ws1 = wb1['Sheet1'] # active sheet database spreadsheet
except:
    print('Error: ' + xlFile + ' failed to open')
    quit()


databaseLastNames = getLastNameList(ws1)  # get list of last names from Excel document
addressLst1 = getAddressLst1(ws1)  # get list of address in column 1 (street address)
pID = getPID(ws1)


for p in range(1, ws1.max_row):
    url = 'https://beacon.schneidercorp.com/Application.aspx?AppID=129&' \
          'LayerID=1554&PageTypeID=4&PageID=817&KeyValue=' + str(pID[p])

    page = requests.get(url)
    soup = BeautifulSoup(page.content, 'html.parser')

    owner = extractOwner(soup).split()[0]  # extracts deeded owners name from HTML, splits the string into component
    # works, and assigns the one at index[0], their last name.

    # extracts deeded owners mailing address from HTML, and splits at the end of street address.
    address = extractAddress(soup)

    lnCheck = lastNameCheck(owner, databaseLastNames, p)
    adCheck = addressCheck(address, addressLst1, p)

    checkOutput(lnCheck, adCheck, wb1, ws1, p)

wb1.save('johnsonX.xlsx')

print('Done')
